{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e51ebb2",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Tutorial TensorFlow: Regression with $$y = x^2$$\n",
    "\n",
    "This Google Colabâ€“friendly notebook shows how to build a simple regression model in **TensorFlow** to learn the quadratic function $$y = x^2$$.\n",
    "\n",
    "Steps covered:\n",
    "1. Install & import libraries\n",
    "2. Generate training data\n",
    "3. Build the model\n",
    "4. Train the model\n",
    "5. Evaluate and visualize results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Install TensorFlow (Colab already has it, but this ensures the latest stable version)\n",
    "!pip install -q tensorflow\n",
    "\n",
    "# ğŸ“š Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df452b",
   "metadata": {},
   "source": [
    "## ğŸ“Š Generate Training Data\n",
    "We will create points in the range $$x \\in [-2, 2]$$ and compute $$y = x^2$$ with optional Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ceb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¢ Generate synthetic data\n",
    "x = np.linspace(-2, 2, 100)\n",
    "y = x ** 2\n",
    "\n",
    "# ğŸ‘‰ Add a bit of noise (optional)\n",
    "y += np.random.normal(0, 0.1, size=y.shape)\n",
    "\n",
    "# ğŸ” Convert to TensorFlow tensors\n",
    "x_train = tf.constant(x.reshape(-1, 1), dtype=tf.float32)\n",
    "y_train = tf.constant(y.reshape(-1, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04f8eb",
   "metadata": {},
   "source": [
    "## ğŸ§  Build the Model\n",
    "We'll use a small **Sequential** network with two hidden layers using **ReLU** activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5855b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—ï¸ Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output scalar\n",
    "])\n",
    "\n",
    "# âš™ï¸ Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26baa455",
   "metadata": {},
   "source": [
    "## âš™ï¸ Train the Model\n",
    "We'll train for 200 epochs and record the Mean Squared Error (MSE) loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b283cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‹ï¸â€â™‚ï¸ Train the model\n",
    "history = model.fit(x_train, y_train, epochs=200, verbose=0)\n",
    "\n",
    "# ğŸ“ˆ Plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1bbf4",
   "metadata": {},
   "source": [
    "## ğŸ” Evaluate & Predict\n",
    "Let's see how well the model approximates $$y = x^2$$ across a finer grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a655e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”® Make predictions on a dense grid\n",
    "x_test = np.linspace(-2, 2, 200).reshape(-1, 1)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# ğŸ“Š Plot predictions vs. true values\n",
    "plt.scatter(x, y, label='True Data', alpha=0.7)\n",
    "plt.plot(x_test, y_pred, label='Model Prediction', linewidth=2)\n",
    "plt.legend()\n",
    "plt.title('Model vs. True Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881b146",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "- We created and trained a simple neural network to model $$y = x^2$$.\n",
    "- Even with a small architecture, TensorFlow can approximate nonlinear functions effectively.\n",
    "\n",
    "Feel free to experiment with the number of layers, neurons, activation functions, and training epochs to see how the model's performance changes!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
